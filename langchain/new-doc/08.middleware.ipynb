{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Middleware 中间件\n",
    "\n",
    "![](https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=1100&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=ec45e1932d1279b1beee4a4b016b473f)"
   ],
   "id": "abdd488a1dfd8c1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 基本用法\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware, HumanInTheLoopMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[],\n",
    "  middleware=[SummarizationMiddleware(), HumanInTheLoopMiddleware()],\n",
    ")"
   ],
   "id": "c296eb14f7a55e87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Built-in middleware 内置中间件",
   "id": "a3da13c10549a507"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Summarization 摘要中间件\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[],\n",
    "  middleware=[\n",
    "    SummarizationMiddleware(\n",
    "      model=\"gpt-4o-mini\",\n",
    "      max_tokens_before_summary=4000,  # 当历史消息超过 4000 个 token 时触发总结\n",
    "      messages_to_keep=20,  # 压缩旧内容后，保留最近的 20 条消息原样（以维持局部上下文）\n",
    "      summary_prompt=\"Custom prompt for summarization...\",  # Optional\n",
    "    ),\n",
    "  ],\n",
    ")"
   ],
   "id": "81fe1d12420e98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T12:31:41.922898Z",
     "start_time": "2025-11-03T12:31:41.331968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2.Human-in-the-loop 人类介入中间件\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "agent = create_agent(\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[],\n",
    "  checkpointer=InMemorySaver(),\n",
    "  middleware=[\n",
    "    HumanInTheLoopMiddleware(\n",
    "      interrupt_on={\n",
    "        # Require approval, editing, or rejection for sending emails\n",
    "        # 智能体每次尝试调用这个工具时，会暂停执行；系统提示人类介入；人类可以审批、编辑或拒绝这个操作。 \n",
    "        \"send_email_tool\": {\n",
    "          \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"],\n",
    "        },\n",
    "        # Auto-approve reading emails\n",
    "        \"read_email_tool\": False,  # 表示无需人工介入；True 表示需要人工介入\n",
    "      }\n",
    "    ),\n",
    "  ],\n",
    ")"
   ],
   "id": "c2fb8768f893d450",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T12:32:32.799969Z",
     "start_time": "2025-11-03T12:32:32.104716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3.Anthropic prompt caching Anthropic 提示缓存\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_anthropic.middleware import AnthropicPromptCachingMiddleware\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "LONG_PROMPT = \"\"\"\n",
    "Please be a helpful assistant.\n",
    "\n",
    "<Lots more context ...>\n",
    "\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "  model=ChatAnthropic(model=\"claude-sonnet-4\"),\n",
    "  system_prompt=LONG_PROMPT,\n",
    "  middleware=[AnthropicPromptCachingMiddleware(ttl=\"5m\")],\n",
    ")\n",
    "\n",
    "# cache store\n",
    "agent.invoke({\"messages\": [HumanMessage(\"Hi, my name is Bob\")]})\n",
    "\n",
    "# cache hit, system prompt is cached\n",
    "agent.invoke({\"messages\": [HumanMessage(\"What's my name?\")]})"
   ],
   "id": "7c4fc1ab0eea8f87",
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': {'type': 'forbidden', 'message': 'Request not allowed'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPermissionDeniedError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 22\u001B[0m\n\u001B[1;32m     15\u001B[0m agent \u001B[38;5;241m=\u001B[39m create_agent(\n\u001B[1;32m     16\u001B[0m     model\u001B[38;5;241m=\u001B[39mChatAnthropic(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclaude-sonnet-4\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     17\u001B[0m     system_prompt\u001B[38;5;241m=\u001B[39mLONG_PROMPT,\n\u001B[1;32m     18\u001B[0m     middleware\u001B[38;5;241m=\u001B[39m[AnthropicPromptCachingMiddleware(ttl\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m5m\u001B[39m\u001B[38;5;124m\"\u001B[39m)],\n\u001B[1;32m     19\u001B[0m )\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# cache store\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mHumanMessage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHi, my name is Bob\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# cache hit, system prompt is cached\u001B[39;00m\n\u001B[1;32m     25\u001B[0m agent\u001B[38;5;241m.\u001B[39minvoke({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [HumanMessage(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhat\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms my name?\u001B[39m\u001B[38;5;124m\"\u001B[39m)]})\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langgraph/pregel/main.py:3094\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001B[0m\n\u001B[1;32m   3091\u001B[0m chunks: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m|\u001B[39m Any] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   3092\u001B[0m interrupts: \u001B[38;5;28mlist\u001B[39m[Interrupt] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 3094\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(\n\u001B[1;32m   3095\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   3096\u001B[0m     config,\n\u001B[1;32m   3097\u001B[0m     context\u001B[38;5;241m=\u001B[39mcontext,\n\u001B[1;32m   3098\u001B[0m     stream_mode\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdates\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   3099\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m stream_mode,\n\u001B[1;32m   3101\u001B[0m     print_mode\u001B[38;5;241m=\u001B[39mprint_mode,\n\u001B[1;32m   3102\u001B[0m     output_keys\u001B[38;5;241m=\u001B[39moutput_keys,\n\u001B[1;32m   3103\u001B[0m     interrupt_before\u001B[38;5;241m=\u001B[39minterrupt_before,\n\u001B[1;32m   3104\u001B[0m     interrupt_after\u001B[38;5;241m=\u001B[39minterrupt_after,\n\u001B[1;32m   3105\u001B[0m     durability\u001B[38;5;241m=\u001B[39mdurability,\n\u001B[1;32m   3106\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3107\u001B[0m ):\n\u001B[1;32m   3108\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   3109\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(chunk) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langgraph/pregel/main.py:2679\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001B[0m\n\u001B[1;32m   2677\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mmatch_cached_writes():\n\u001B[1;32m   2678\u001B[0m     loop\u001B[38;5;241m.\u001B[39moutput_writes(task\u001B[38;5;241m.\u001B[39mid, task\u001B[38;5;241m.\u001B[39mwrites, cached\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m-> 2679\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mtick(\n\u001B[1;32m   2680\u001B[0m     [t \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m t\u001B[38;5;241m.\u001B[39mwrites],\n\u001B[1;32m   2681\u001B[0m     timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[1;32m   2682\u001B[0m     get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[1;32m   2683\u001B[0m     schedule_task\u001B[38;5;241m=\u001B[39mloop\u001B[38;5;241m.\u001B[39maccept_push,\n\u001B[1;32m   2684\u001B[0m ):\n\u001B[1;32m   2685\u001B[0m     \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[1;32m   2686\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _output(\n\u001B[1;32m   2687\u001B[0m         stream_mode, print_mode, subgraphs, stream\u001B[38;5;241m.\u001B[39mget, queue\u001B[38;5;241m.\u001B[39mEmpty\n\u001B[1;32m   2688\u001B[0m     )\n\u001B[1;32m   2689\u001B[0m loop\u001B[38;5;241m.\u001B[39mafter_tick()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langgraph/pregel/_runner.py:167\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001B[0m\n\u001B[1;32m    165\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 167\u001B[0m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m                \u001B[49m\u001B[43m_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m                \u001B[49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m                \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m                \u001B[49m\u001B[43mfutures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m                \u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschedule_task\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m                \u001B[49m\u001B[43msubmit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langgraph/pregel/_retry.py:42\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy, configurable)\u001B[0m\n\u001B[1;32m     40\u001B[0m     task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     44\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:656\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    654\u001B[0m     \u001B[38;5;66;03m# run in context\u001B[39;00m\n\u001B[1;32m    655\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(config, run) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[0;32m--> 656\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    657\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    658\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:400\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    398\u001B[0m         run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(ret)\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 400\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable):\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain/agents/factory.py:1037\u001B[0m, in \u001B[0;36mcreate_agent.<locals>.model_node\u001B[0;34m(state, runtime)\u001B[0m\n\u001B[1;32m   1034\u001B[0m     response \u001B[38;5;241m=\u001B[39m _execute_model_sync(request)\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1036\u001B[0m     \u001B[38;5;66;03m# Call composed handler with base handler\u001B[39;00m\n\u001B[0;32m-> 1037\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mwrap_model_call_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_execute_model_sync\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;66;03m# Extract state updates from ModelResponse\u001B[39;00m\n\u001B[1;32m   1040\u001B[0m state_updates \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: response\u001B[38;5;241m.\u001B[39mresult}\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain/agents/factory.py:125\u001B[0m, in \u001B[0;36m_chain_model_call_handlers.<locals>.normalized_single\u001B[0;34m(request, handler)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mnormalized_single\u001B[39m(\n\u001B[1;32m    122\u001B[0m     request: ModelRequest,\n\u001B[1;32m    123\u001B[0m     handler: Callable[[ModelRequest], ModelResponse],\n\u001B[1;32m    124\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModelResponse:\n\u001B[0;32m--> 125\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43msingle_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhandler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _normalize_to_model_response(result)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain_anthropic/middleware/prompt_caching.py:123\u001B[0m, in \u001B[0;36mAnthropicPromptCachingMiddleware.wrap_model_call\u001B[0;34m(self, request, handler)\u001B[0m\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handler(request)\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_cache_control(request)\n\u001B[0;32m--> 123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhandler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain/agents/factory.py:1007\u001B[0m, in \u001B[0;36mcreate_agent.<locals>._execute_model_sync\u001B[0;34m(request)\u001B[0m\n\u001B[1;32m   1004\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m request\u001B[38;5;241m.\u001B[39msystem_prompt:\n\u001B[1;32m   1005\u001B[0m     messages \u001B[38;5;241m=\u001B[39m [SystemMessage(request\u001B[38;5;241m.\u001B[39msystem_prompt), \u001B[38;5;241m*\u001B[39mmessages]\n\u001B[0;32m-> 1007\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1009\u001B[0m \u001B[38;5;66;03m# Handle model output to get messages and structured_response\u001B[39;00m\n\u001B[1;32m   1010\u001B[0m handled_output \u001B[38;5;241m=\u001B[39m _handle_model_output(output, effective_response_format)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain_core/runnables/base.py:5489\u001B[0m, in \u001B[0;36mRunnableBindingBase.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   5482\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m   5483\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m   5484\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5487\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   5488\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Output:\n\u001B[0;32m-> 5489\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbound\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5490\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5491\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5492\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5493\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:379\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    367\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    373\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m AIMessage:\n\u001B[1;32m    374\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    376\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAIMessage\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    377\u001B[0m         cast(\n\u001B[1;32m    378\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChatGeneration\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m--> 379\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m                \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m                \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    389\u001B[0m         )\u001B[38;5;241m.\u001B[39mmessage,\n\u001B[1;32m    390\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1088\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m   1079\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m   1081\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1085\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m   1086\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m   1087\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m-> 1088\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:903\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[1;32m    901\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    902\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 903\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    907\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    908\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    909\u001B[0m         )\n\u001B[1;32m    910\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    911\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1192\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m     result \u001B[38;5;241m=\u001B[39m generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1192\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   1194\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1196\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain_anthropic/chat_models.py:1856\u001B[0m, in \u001B[0;36mChatAnthropic._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m   1854\u001B[0m payload \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_request_payload(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1855\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1856\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1857\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m anthropic\u001B[38;5;241m.\u001B[39mBadRequestError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1858\u001B[0m     _handle_anthropic_bad_request(e)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/langchain_anthropic/chat_models.py:1718\u001B[0m, in \u001B[0;36mChatAnthropic._create\u001B[0;34m(self, payload)\u001B[0m\n\u001B[1;32m   1716\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m payload:\n\u001B[1;32m   1717\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mbeta\u001B[38;5;241m.\u001B[39mmessages\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpayload)\n\u001B[0;32m-> 1718\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/anthropic/_utils/_utils.py:282\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    280\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/anthropic/resources/messages/messages.py:927\u001B[0m, in \u001B[0;36mMessages.create\u001B[0;34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m DEPRECATED_MODELS:\n\u001B[1;32m    921\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    922\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe model \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is deprecated and will reach end-of-life on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mDEPRECATED_MODELS[model]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    923\u001B[0m         \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m,\n\u001B[1;32m    924\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m    925\u001B[0m     )\n\u001B[0;32m--> 927\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/v1/messages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    931\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    932\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    933\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    934\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    935\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    936\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop_sequences\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop_sequences\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    938\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msystem\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43msystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    939\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    940\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthinking\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mthinking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    941\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    942\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    943\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_k\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    944\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessage_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMessageCreateParamsStreaming\u001B[49m\n\u001B[1;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[1;32m    948\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmessage_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMessageCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    949\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    950\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    951\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    953\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMessage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    954\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    955\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mRawMessageStreamEvent\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    956\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/anthropic/_base_client.py:1324\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1310\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1311\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1312\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1319\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1320\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1321\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1322\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1323\u001B[0m     )\n\u001B[0;32m-> 1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/py310/lib/python3.10/site-packages/anthropic/_base_client.py:1112\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1109\u001B[0m             err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1111\u001B[0m         log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1112\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1114\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1116\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not resolve response (should never happen)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mPermissionDeniedError\u001B[0m: Error code: 403 - {'error': {'type': 'forbidden', 'message': 'Request not allowed'}}"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T12:33:30.782998Z",
     "start_time": "2025-11-03T12:33:30.776706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Model call limit 模型调用限制\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[],\n",
    "  middleware=[\n",
    "    ModelCallLimitMiddleware(\n",
    "      thread_limit=10,  # 每个线程最多允许10次模型调用\n",
    "      run_limit=5,  # 单次运行（一次 invoke）最多5次模型调用\n",
    "      exit_behavior=\"end\",  # 达到上限后的行为\n",
    "    ),\n",
    "  ],\n",
    ")"
   ],
   "id": "bca08eecfcce5bf5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 5.Model fallback 模型回退\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ModelFallbackMiddleware\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",  # Primary model\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        ModelFallbackMiddleware(\n",
    "            \"gpt-4o-mini\",  # Try first on error\n",
    "            \"claude-3-5-sonnet-20241022\",  # Then this\n",
    "        ),\n",
    "    ],\n",
    ")"
   ],
   "id": "78c67cdd3cc0f8dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 6.个人身份信息检测\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[],\n",
    "    middleware=[\n",
    "        # Redact emails in user input\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\", apply_to_input=True),\n",
    "        # Mask credit cards (show last 4 digits)\n",
    "        PIIMiddleware(\"credit_card\", strategy=\"mask\", apply_to_input=True),\n",
    "        # Custom PII type with regex\n",
    "        PIIMiddleware(\n",
    "            \"api_key\",\n",
    "            detector=r\"sk-[a-zA-Z0-9]{32}\",\n",
    "            strategy=\"block\",  # Raise error if detected\n",
    "        ),\n",
    "    ],\n",
    ")"
   ],
   "id": "a527073b2db3e7ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T12:43:58.534717Z",
     "start_time": "2025-11-03T12:40:26.403926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7.规划\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import TodoListMiddleware\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=[],\n",
    "    middleware=[TodoListMiddleware()],\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [HumanMessage(\"Help me refactor my codebase\")]})\n",
    "print(result[\"todos\"])  # Array of todo items with status tracking"
   ],
   "id": "3ff4a30ac55c9235",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Gather key details about the codebase (language, frameworks, size, repo access, goals, pain points)', 'status': 'in_progress'}, {'content': 'Obtain repository link or representative code samples (or a directory tree) to review', 'status': 'pending'}, {'content': 'Confirm how to build/run/tests locally and CI details', 'status': 'pending'}, {'content': 'Define refactoring objectives and constraints with you (maintainability, performance, testability, API stability, deadlines)', 'status': 'pending'}, {'content': 'Set up or review linting/static analysis tooling appropriate for the stack', 'status': 'pending'}, {'content': 'Run a quick audit to identify hot spots (complexity, duplication, dead code, outdated deps)', 'status': 'pending'}, {'content': 'Draft a prioritized refactoring plan with milestones and small PRs', 'status': 'pending'}, {'content': 'Execute the first refactor on a low-risk area and ensure tests pass', 'status': 'pending'}, {'content': 'Document changes and add guidelines to the repo (README/CONTRIBUTING)', 'status': 'pending'}]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 8. LLM 工具选择器\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import LLMToolSelectorMiddleware\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[tool1, tool2, tool3, tool4, tool5, ...],  # Many tools\n",
    "    middleware=[\n",
    "        LLMToolSelectorMiddleware(\n",
    "            model=\"gpt-4o-mini\",  # Use cheaper model for selection\n",
    "            max_tools=3,  # Limit to 3 most relevant tools\n",
    "            always_include=[\"search\"],  # Always include certain tools\n",
    "        ),\n",
    "    ],\n",
    ")"
   ],
   "id": "73030424b163aeaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 9.工具重试\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ToolRetryMiddleware\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[search_tool, database_tool],\n",
    "    middleware=[\n",
    "        ToolRetryMiddleware(\n",
    "            max_retries=3,  # Retry up to 3 times\n",
    "            backoff_factor=2.0,  # Exponential backoff multiplier\n",
    "            initial_delay=1.0,  # Start with 1 second delay\n",
    "            max_delay=60.0,  # Cap delays at 60 seconds\n",
    "            jitter=True,  # Add random jitter to avoid thundering herd\n",
    "        ),\n",
    "    ],\n",
    ")"
   ],
   "id": "7739316b6b130927"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 10.LLM 工具模拟器\n",
    "\n",
    "# 但在很多场景下——你只是想测试智能体的行为或不想调用真实 API（例如发邮件、操作数据库）——就可以启用 LLMToolEmulator\n",
    "# 它的作用是：“当模型想用工具时，不让它真的执行工具，而是让模型自己编造工具的返回结果。”\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import LLMToolEmulator\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[get_weather, search_database, send_email],\n",
    "    middleware=[\n",
    "        # Emulate all tools by default\n",
    "        LLMToolEmulator(),\n",
    "\n",
    "        # Or emulate specific tools\n",
    "        # LLMToolEmulator(tools=[\"get_weather\", \"search_database\"]),\n",
    "\n",
    "        # Or use a custom model for emulation\n",
    "        # LLMToolEmulator(model=\"claude-sonnet-4-5-20250929\"),\n",
    "    ],\n",
    ")\n"
   ],
   "id": "8bffbf46b49238d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 11.上下文编辑\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ContextEditingMiddleware, ClearToolUsesEdit\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[...],\n",
    "    middleware=[\n",
    "        # 中间件在模型运行前被触发，它的参数 edits=[...] 是一个编辑规则列表。\n",
    "        ContextEditingMiddleware(\n",
    "            edits=[\n",
    "                # 这是一个编辑器，用来在上下文中删除或压缩旧的工具使用记录。\n",
    "                # 模型每次调用前，会检查历史上下文（messages）；\n",
    "                # 如果之前的工具调用总长度超过 max_tokens=1000；\n",
    "                # 它就会删除或截断旧的工具使用内容，只保留最近的部分。\n",
    "                \n",
    "                # 相当于告诉模型：“忘掉太久以前那些工具调用细节，只记住最近 1000 token 的内容。”\n",
    "                ClearToolUsesEdit(max_tokens=1000),  # Clear old tool uses\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    ")"
   ],
   "id": "509469edc9e25de8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 自定义中间件\n",
    "\n",
    "您可以通过两种方式创建中间件：\n",
    "- 基于装饰器 - 对于单钩子中间件快速且简单\n",
    "- 基于类 - 对于具有多个钩子的复杂中间件更强大\n",
    "​\n"
   ],
   "id": "8d0174125cee7a26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "923d2a3d609d91b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.基于装饰器的中间件",
   "id": "204bcfc048180d9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 基于装饰器的中间件\n",
    "\n",
    "from langchain.agents.middleware import before_model, after_model, wrap_model_call\n",
    "from langchain.agents.middleware import AgentState, ModelRequest, ModelResponse, dynamic_prompt\n",
    "from langchain.messages import AIMessage\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any, Callable\n",
    "\n",
    "\n",
    "# Node-style: logging before model calls\n",
    "@before_model\n",
    "def log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    print(f\"About to call model with {len(state['messages'])} messages\")\n",
    "    return None\n",
    "\n",
    "# Node-style: validation after model calls\n",
    "@after_model(can_jump_to=[\"end\"])\n",
    "def validate_output(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"BLOCKED\" in last_message.content:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(\"I cannot respond to that request.\")],\n",
    "            \"jump_to\": \"end\"\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Wrap-style: retry logic\n",
    "@wrap_model_call\n",
    "def retry_model(\n",
    "    request: ModelRequest,\n",
    "    handler: Callable[[ModelRequest], ModelResponse],\n",
    ") -> ModelResponse:\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            return handler(request)\n",
    "        except Exception as e:\n",
    "            if attempt == 2:\n",
    "                raise\n",
    "            print(f\"Retry {attempt + 1}/3 after error: {e}\")\n",
    "\n",
    "# Wrap-style: dynamic prompts\n",
    "@dynamic_prompt\n",
    "def personalized_prompt(request: ModelRequest) -> str:\n",
    "    user_id = request.runtime.context.get(\"user_id\", \"guest\")\n",
    "    return f\"You are a helpful assistant for user {user_id}. Be concise and friendly.\"\n",
    "\n",
    "# Use decorators in agent\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    middleware=[log_before_model, validate_output, retry_model, personalized_prompt],\n",
    "    tools=[...],\n",
    ")"
   ],
   "id": "95fc5e3182eadf24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.基于装饰器的中间件",
   "id": "4c019e8281b62a61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 示例：日志中间件\n",
    "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "class LoggingMiddleware(AgentMiddleware):\n",
    "    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        print(f\"About to call model with {len(state['messages'])} messages\")\n",
    "        return None\n",
    "\n",
    "    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        print(f\"Model returned: {state['messages'][-1].content}\")\n",
    "        return None"
   ],
   "id": "a5718ad8aedfefec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T12:59:30.382980Z",
     "start_time": "2025-11-03T12:59:30.379455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 示例：对话长度限制\n",
    "from langchain.agents.middleware import AgentMiddleware, AgentState\n",
    "from langchain.messages import AIMessage\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "\n",
    "class MessageLimitMiddleware(AgentMiddleware):\n",
    "    def __init__(self, max_messages: int = 50):\n",
    "        super().__init__()\n",
    "        self.max_messages = max_messages\n",
    "\n",
    "    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "        if len(state[\"messages\"]) == self.max_messages:\n",
    "            return {\n",
    "                \"messages\": [AIMessage(\"Conversation limit reached.\")],\n",
    "                \"jump_to\": \"end\"\n",
    "            }\n",
    "        return None"
   ],
   "id": "a51d095c650fb9e0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ff411003676ba523"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 最佳实践\n",
    "- 保持中间件专注 - 每个中间件应做好一件事\n",
    "- 优雅地处理错误 - 不要让中间件错误导致代理崩溃\n",
    "- 使用适当的钩子类型 ：\n",
    "- 用于顺序逻辑的节点风格（日志记录、验证）\n",
    "- 控制流的包装样式（重试、后备、缓存）\n",
    "- 清晰记录任何自定义状态属性\n",
    "- 在集成之前独立单元测试中间件\n",
    "- 考虑执行顺序 - 将关键中间件放在列表的最前面\n",
    "- 尽可能使用内置中间件，不要重复造轮子 :)"
   ],
   "id": "a89acab93fa11bde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b8236f9c6be3424"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
