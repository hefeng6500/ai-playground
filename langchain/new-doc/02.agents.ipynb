{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896a40e5b1f5fa84",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e5393113cea52",
   "metadata": {},
   "source": [
    "## 1.静态模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b3d823cee7b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    \"openai:gpt-5\",\n",
    "    tools=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-5\",\n",
    "    temperature=0.7,\n",
    "     max_tokens=4096,\n",
    "    timeout=30,\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    answer: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a concise assistant. Answer clearly and briefly.\",\n",
    "    response_format=ResponseFormat\n",
    "    # tools=[]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"人生的意义是什么?\"}]}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(response)) # or use print(response.keys())\n",
    "print(response[\"structured_response\"].answer)\n",
    "print(response['messages'])  # 转换为标准字典\n",
    "\n",
    "print(dict(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872845c2a3d21fad",
   "metadata": {},
   "source": [
    "## 2.动态模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7513d02ed4ef5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "创建一个智能体，它会在对话早期使用轻量、便宜的 gpt-4.1-mini，当对话变长时自动切换到更强大的 gpt-5。这样既能节省成本，又能保证复杂任务的质量。\n",
    "\"\"\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "basic_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "advanced_model = ChatOpenAI(model=\"gpt-5\")\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 10:\n",
    "        # Use an advanced model for longer conversations\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    request.model = model\n",
    "    return handler(request)\n",
    "\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    answer: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,  # Default model\n",
    "    tools=[],\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    middleware=[dynamic_model_selection],\n",
    "    response_format=ResponseFormat,\n",
    ")\n",
    "\n",
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"如何学习 LangChain V1.0.0?\"}]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"structured_response\"].answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf77184b34ba9c5",
   "metadata": {},
   "source": [
    "## 3.工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665a44058790eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_tool_call\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get weather information for a location.\"\"\"\n",
    "    if not location or location.strip() == \"\":\n",
    "        raise ValueError(\"Missing required parameter: location\")\n",
    "    return f\"Weather in {location}: Sunny, 72°F\"\n",
    "\n",
    "# 自定义如何处理工具错误\n",
    "@wrap_tool_call\n",
    "def handle_tool_errors(request, handler):\n",
    "    \"\"\"Handle tool execution errors with custom messages.\"\"\"\n",
    "    try:\n",
    "        return handler(request)\n",
    "    except Exception as e:\n",
    "        # Return a custom error message to the model\n",
    "        return ToolMessage(\n",
    "            content=f\"Tool error: Please check your input and try again. ({str(e)})\",\n",
    "            tool_call_id=request.tool_call[\"id\"]\n",
    "        )\n",
    "# ⚡ 关键点：自定义 system prompt\n",
    "system_prompt = \"\"\"You are a helpful AI assistant.\n",
    "You have access to tools.\n",
    "If the user input is ambiguous or missing required parameters, DO NOT ask for clarification.\n",
    "Instead, call the tool anyway with empty or default values.\n",
    "\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o\",\n",
    "    tools=[search, get_weather],\n",
    "    middleware=[handle_tool_errors],\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather?\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(response) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66a626",
   "metadata": {},
   "source": [
    "## System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55168d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 动态系统提示\n",
    "from typing import TypedDict\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate system prompt based on user role.\"\"\"\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"user\")\n",
    "    base_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_role == \"expert\":\n",
    "        return f\"{base_prompt} Provide detailed technical responses.\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return f\"{base_prompt} Explain concepts simply and avoid jargon.\"\n",
    "\n",
    "    return base_prompt\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o\",\n",
    "    tools=[],\n",
    "    middleware=[user_role_prompt],\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# The system prompt will be set dynamically based on context\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"解释机器学习\"}]},\n",
    "    context={\"user_role\": \"beginner\"}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"messages\"])\n",
    "ai_message = result[\"messages\"][1]\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6481064",
   "metadata": {},
   "source": [
    "## Invocation 调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814df311",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6614578",
   "metadata": {},
   "source": [
    "## Structured output 结构化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd00dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ToolStrategy\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[],\n",
    "    response_format=ToolStrategy(ContactInfo)\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc87b68",
   "metadata": {},
   "source": [
    "## ToolStrategy 解释说明\n",
    "\n",
    "`ToolStrategy(ResponseFormat)` 是 `@dataclass ResponseFormat` 的增强版\n",
    "\n",
    "### 两者的本质区别\n",
    "| 对比项        | `ToolStrategy(ContactInfo)`            | `@dataclass ResponseFormat`       |\n",
    "| ---------- | -------------------------------------- | --------------------------------- |\n",
    "| **定位**     | LangChain 新版 **“工具策略（Tool Strategy）”** | 传统 **结构化输出模式（Structured Output）** |\n",
    "| **主要作用**   | 控制模型调用工具的输入/输出格式                       | 约束模型的最终输出结构                       |\n",
    "| **典型使用场景** | Agent 调用多个工具，返回值结构化                    | 模型输出固定 JSON 样式的结果                 |\n",
    "| **底层语义**   | 模型需遵循工具协作协议                            | 模型需直接生成符合 schema 的 JSON           |\n",
    "| **解析逻辑**   | 由 `ToolStrategy` 处理工具调用的 I/O           | 由 `response_format` 解析为对象或字典      |\n",
    "\n",
    "### 底层差异总结\n",
    "| 层级           | ToolStrategy     | Dataclass   |\n",
    "| ------------ | ---------------- | ----------- |\n",
    "| 调用层          | Agent 工具策略层      | 模型输出解析层     |\n",
    "| 语义           | “如何调用工具并返回结构化数据” | “如何生成结构化输出” |\n",
    "| 是否需要工具       | ✅ 可有工具           | ❌ 通常无工具     |\n",
    "| LangChain 版本 | 0.2+ 新版推荐写法      | 旧版（兼容但简化）   |\n",
    "| 扩展性          | 可定义多工具行为策略       | 仅定义单输出结构    |\n",
    "\n",
    "### 企业最佳实践建议\n",
    "| 场景                         | 推荐写法                           |\n",
    "| -------------------------- | ------------------------------ |\n",
    "| 智能体调用多个 API / 工具，需要统一返回结构  | ✅ `ToolStrategy(BaseModel)`    |\n",
    "| 只是需要模型输出固定 JSON 结构（如总结、提取） | ✅ `@dataclass response_format` |\n",
    "| 需要可扩展策略（错误处理、参数检查、可控调用）    | ✅ `ToolStrategy` 更优            |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d0fd25",
   "metadata": {},
   "source": [
    "## Memory\n",
    "\n",
    "状态中存储的信息可以被视为代理的短期记忆\n",
    "\n",
    "定义自定义状态有两种方法:\n",
    "- 通过中间件 （推荐）\n",
    "- 通过 state_schema 在 create_agent 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过中间件\n",
    "\n",
    "from langchain.agents import AgentState\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_preferences: dict\n",
    "\n",
    "class CustomMiddleware(AgentMiddleware):\n",
    "    state_schema = CustomState\n",
    "    tools = []\n",
    "\n",
    "    def before_model(self, state: CustomState, runtime):\n",
    "        \"\"\"\n",
    "        在模型调用前对消息做预处理。\n",
    "        \"\"\"\n",
    "        prefs = state.get(\"user_preferences\", {})\n",
    "\n",
    "        # 在对话前插入一条系统提示，指引模型如何回答\n",
    "        if prefs:\n",
    "            style = prefs.get(\"style\", \"neutral\")\n",
    "            verbosity = prefs.get(\"verbosity\", \"normal\")\n",
    "            instruction = f\"回答风格：{style}；详细程度：{verbosity}。\"\n",
    "            return {\n",
    "                \"messages\": state[\"messages\"] + [{\"role\": \"system\", \"content\": instruction}]\n",
    "            }\n",
    "        return None\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[],\n",
    "    middleware=[CustomMiddleware()]\n",
    ")\n",
    "\n",
    "# The agent can now track additional state beyond messages\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"请介绍一下 LangChain\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})\n",
    "\n",
    "print(result['messages'][1].content) # SystemMessage\n",
    "print(result['messages'][2].content) # AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33cd687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 state_schema 参数作为快捷方式来定义仅在工具中使用的自定义状态。\n",
    "\n",
    "from langchain.agents import AgentState\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for a query.\"\"\"\n",
    "    return f\"Search results for {query}\"\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[search],\n",
    "    state_schema=CustomState\n",
    ")\n",
    "# The agent can now track additional state beyond messages\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"介绍 LangChain\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfe059",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "def search_ai_news(query: str) -> str:\n",
    "    \"\"\"Search for AI news articles.\"\"\"\n",
    "    return f\"AI news about {query}\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    tools=[search_ai_news],\n",
    ")\n",
    "for chunk in agent.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Search for AI news and summarize the findings\"}]\n",
    "}, stream_mode=\"values\"):\n",
    "    # Each chunk contains the full state at that point\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    if latest_message.content:\n",
    "        print(f\"Agent: {latest_message.content}\", end=\"\", flush=True)\n",
    "    elif latest_message.tool_calls:\n",
    "        print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\", end=\"\", flush=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 初始化模型\n",
    "model = init_chat_model(\"openai:gpt-5-nano\")\n",
    "\n",
    "# 直接流式打印 token\n",
    "for chunk in model.stream(\"Explain the future of AI in 5 steps.\"):\n",
    "    print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ba32876aa9c31",
   "metadata": {},
   "source": [
    "## 3.1 传递配置好的 ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349de780edb334d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ToolNode\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    tools=[search, calculate],\n",
    "    handle_tool_errors=\"Please check your input and try again.\"\n",
    ")\n",
    "agent = create_agent(model, tools=tool_node)\n",
    "result = agent.invoke({\"messages\": [...]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a9e98593a3c06a",
   "metadata": {},
   "source": [
    "## 4.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e99d08c2555816",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    prompt=\"You are a helpful assistant. Be concise and accurate.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b030fa00aea8230",
   "metadata": {},
   "source": [
    "## 高级配置 -- 结构化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f629d020d4e25b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[search_tool],\n",
    "    response_format=ContactInfo\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be17dacf1dca14e",
   "metadata": {},
   "source": [
    "## 高级配置 -- 记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f5c669a3689f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents import AgentState\n",
    "\n",
    "class CustomAgentState(AgentState):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    state_schema=CustomAgentState\n",
    ")\n",
    "\n",
    "# The agent can now track additional state beyond messages. This custom state can be accessed and updated throughout the conversation.\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"I prefer technical explanations\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0575c3dd2f396",
   "metadata": {},
   "source": [
    "## 高级配置 -- 模型前钩子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec06bd2af4451a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "def trim_messages(state):\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return {\"messages\": messages}\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    pre_model_hook=trim_messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388b1fffd6c386b",
   "metadata": {},
   "source": [
    "## 高级配置 --  模型后钩子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1e93d308d8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "\n",
    "def validate_response(state):\n",
    "    \"\"\"Check model response for policy violations.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    ## confidential 机密\n",
    "    if \"confidential\" in last_message.content.lower():\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "                *messages[:-1],\n",
    "                AIMessage(content=\"I cannot share confidential information.\")\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    return {}\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    post_model_hook=validate_response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d987f995bf6ede",
   "metadata": {},
   "source": [
    "## 高级配置 -- 流式传输"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31244391ff58ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Search for AI news and summarize the findings\"}]\n",
    "}, stream_mode=\"values\"):\n",
    "    # Each chunk contains the full state at that point\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    if latest_message.content:\n",
    "        print(f\"Agent: {latest_message.content}\")\n",
    "    elif latest_message.tool_calls:\n",
    "        print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2263a8ac06bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 流失输出 demo\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "# 1. 定义一个最简单的工具\n",
    "@tool\n",
    "def search_ai_news(query: str) -> str:\n",
    "    \"\"\"Search the latest AI news (dummy implementation).\"\"\"\n",
    "    return f\"Found some dummy AI news for query: {query}\"\n",
    "\n",
    "\n",
    "# 2. 定义模型（这里用 OpenAI）\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 3. 创建 agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search_ai_news]\n",
    ")\n",
    "\n",
    "# 4. 运行并流式打印结果\n",
    "for chunk in agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Search for AI news and summarize the findings\"}\n",
    "        ]\n",
    "    },\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    # 每个 chunk 是当前状态\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    if latest_message.content:\n",
    "        print(f\"Agent: {latest_message.content}\")\n",
    "    elif latest_message.tool_calls:\n",
    "        print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
