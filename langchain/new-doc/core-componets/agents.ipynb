{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agents",
   "id": "896a40e5b1f5fa84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.静态模型ß",
   "id": "ec3e5393113cea52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-3.5-turbo\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "  \"\"\"Get weather for a given city.\"\"\"\n",
    "  return f\"It's always sunny in {city}!\"\n",
    "\n",
    "tools=[get_weather],"
   ],
   "id": "c2fa0dce5b7887c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    \"openai:gpt-5\",\n",
    "    tools=[]\n",
    ")"
   ],
   "id": "179b3d823cee7b43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.动态模型",
   "id": "872845c2a3d21fad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "创建一个智能体，它会在对话早期使用轻量、便宜的 gpt-4.1-mini，当对话变长时自动切换到更强大的 gpt-5。这样既能节省成本，又能保证复杂任务的质量。\n",
    "\"\"\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langgraph.runtime import Runtime\n",
    "\n",
    "def select_model(state: AgentState, runtime: Runtime) -> ChatOpenAI:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    message_count = len(messages)\n",
    "\n",
    "    if message_count < 10:\n",
    "        return ChatOpenAI(model=\"gpt-4.1-mini\").bind_tools(tools)\n",
    "    else:\n",
    "        return ChatOpenAI(model=\"gpt-5\").bind_tools(tools) # Better model for longer conversations\n",
    "\n",
    "agent = create_agent(select_model, tools=tools)"
   ],
   "id": "b7513d02ed4ef5c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.工具",
   "id": "8bf77184b34ba9c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Perform calculations.\"\"\"\n",
    "    return str(eval(expression))\n",
    "\n",
    "agent = create_agent(model, tools=[search, calculate])"
   ],
   "id": "1665a44058790eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 传递配置好的 ToolNode",
   "id": "bd9ba32876aa9c31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.agents import ToolNode\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    tools=[search, calculate],\n",
    "    handle_tool_errors=\"Please check your input and try again.\"\n",
    ")\n",
    "agent = create_agent(model, tools=tool_node)\n",
    "result = agent.invoke({\"messages\": [...]})"
   ],
   "id": "349de780edb334d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.prompt",
   "id": "d3a9e98593a3c06a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "agent = create_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    prompt=\"You are a helpful assistant. Be concise and accurate.\"\n",
    ")"
   ],
   "id": "a4e99d08c2555816",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 高级配置 -- 结构化输出",
   "id": "4b030fa00aea8230"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=[search_tool],\n",
    "    response_format=ContactInfo\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
   ],
   "id": "f629d020d4e25b97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 高级配置 -- 记忆",
   "id": "5be17dacf1dca14e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import TypedDict\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents import AgentState\n",
    "\n",
    "class CustomAgentState(AgentState):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_preferences: dict\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    state_schema=CustomAgentState\n",
    ")\n",
    "\n",
    "# The agent can now track additional state beyond messages. This custom state can be accessed and updated throughout the conversation.\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"I prefer technical explanations\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})"
   ],
   "id": "578f5c669a3689f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 高级配置 -- 模型前钩子",
   "id": "79b0575c3dd2f396"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "def trim_messages(state):\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return {\"messages\": messages}\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    pre_model_hook=trim_messages\n",
    ")"
   ],
   "id": "7ec06bd2af4451a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 高级配置 --  模型后钩子",
   "id": "2388b1fffd6c386b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.messages import AIMessage, RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "\n",
    "def validate_response(state):\n",
    "    \"\"\"Check model response for policy violations.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    ## confidential 机密\n",
    "    if \"confidential\" in last_message.content.lower():\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "                *messages[:-1],\n",
    "                AIMessage(content=\"I cannot share confidential information.\")\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    return {}\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=tools,\n",
    "    post_model_hook=validate_response\n",
    ")"
   ],
   "id": "a9c1e93d308d8c8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 高级配置 -- 流式传输",
   "id": "63d987f995bf6ede"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for chunk in agent.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Search for AI news and summarize the findings\"}]\n",
    "}, stream_mode=\"values\"):\n",
    "    # Each chunk contains the full state at that point\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    if latest_message.content:\n",
    "        print(f\"Agent: {latest_message.content}\")\n",
    "    elif latest_message.tool_calls:\n",
    "        print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\")"
   ],
   "id": "31244391ff58ed9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T07:31:00.411927Z",
     "start_time": "2025-09-24T07:30:56.612093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 流失输出 demo\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "# 1. 定义一个最简单的工具\n",
    "@tool\n",
    "def search_ai_news(query: str) -> str:\n",
    "    \"\"\"Search the latest AI news (dummy implementation).\"\"\"\n",
    "    return f\"Found some dummy AI news for query: {query}\"\n",
    "\n",
    "\n",
    "# 2. 定义模型（这里用 OpenAI）\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 3. 创建 agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search_ai_news]\n",
    ")\n",
    "\n",
    "# 4. 运行并流式打印结果\n",
    "for chunk in agent.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"Search for AI news and summarize the findings\"}\n",
    "        ]\n",
    "    },\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    # 每个 chunk 是当前状态\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    if latest_message.content:\n",
    "        print(f\"Agent: {latest_message.content}\")\n",
    "    elif latest_message.tool_calls:\n",
    "        print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\")\n"
   ],
   "id": "fb2263a8ac06bef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Search for AI news and summarize the findings\n",
      "Calling tools: ['search_ai_news']\n",
      "Agent: Found some dummy AI news for query: latest AI news\n",
      "Agent: Here is a summary of the latest AI news:\n",
      "\n",
      "- There have been recent advancements in AI technologies, including improvements in natural language processing and computer vision.\n",
      "- New AI models have been released that offer better performance and efficiency.\n",
      "- AI is increasingly being integrated into various industries such as healthcare, finance, and autonomous vehicles.\n",
      "- Ethical considerations and regulations around AI development and deployment continue to be a significant topic of discussion.\n",
      "- Research in AI safety and interpretability is gaining more attention to ensure responsible AI use.\n",
      "\n",
      "If you want, I can provide more detailed information on any specific area of AI news.\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
