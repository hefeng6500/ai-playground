{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Models",
   "id": "3bc583aebb7345ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"openai:gpt-5-nano\")\n",
    "response = model.invoke(\"Why do parrots talk?\")\n",
    "\n",
    "print(response)"
   ],
   "id": "d74cf04036e0f2ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 模型传入的参数\n",
    "\n",
    "- model\n",
    "- api_key\n",
    "- temperature\n",
    "- max_tokens\n",
    "- max-retries\n",
    "\n"
   ],
   "id": "cdadf60c9f70ad62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. 调用",
   "id": "925270bef16e4aa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = model.invoke(\"Why do parrots have colorful feathers?\")\n",
    "print(response)"
   ],
   "id": "bb959fa5f34802cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "conversation = [\n",
    "    SystemMessage(\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(\"Translate: I love programming.\"),\n",
    "    AIMessage(\"J'adore la programmation.\"),\n",
    "    HumanMessage(\"Translate: I love building applications.\")\n",
    "]\n",
    "\n",
    "response = model.invoke(conversation)\n",
    "print(response)  # AIMessage(\"J'adore créer des applications.\")"
   ],
   "id": "c806c20967fe4c0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 流式传输",
   "id": "2f309f068fbee1b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for chunk in model.stream(\"Why do parrots have colorful feathers?\"):\n",
    "    print(chunk.text, end=\"|\", flush=True)"
   ],
   "id": "5c61bad4ba517cca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full = None  # None | AIMessageChunk\n",
    "for chunk in model.stream(\"What color is the sky?\"):\n",
    "    full = chunk if full is None else full + chunk\n",
    "    print(full.text)\n",
    "\n",
    "# The\n",
    "# The sky\n",
    "# The sky is\n",
    "# The sky is typically\n",
    "# The sky is typically blue\n",
    "# ...\n",
    "\n",
    "print(full.content)\n",
    "# Usually blue during the day. That blue comes from Rayleigh scattering: sunlight hits the atmosphere and the shorter blue wavelengths scatter in all directions. The color can change: red/orange/pink at sunrise and sunset, gray on cloudy days, and dark at night (with stars visible). Want the answer for a specific time or place?"
   ],
   "id": "7b8965f8f60d0d9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 批量 Batch",
   "id": "8608d0b4d4126253"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 返回整个批次的最终输出\n",
    "responses = model.batch([\n",
    "    \"Why do parrots have colorful feathers?\",\n",
    "    \"How do airplanes fly?\",\n",
    "    \"What is quantum computing?\"\n",
    "])\n",
    "for response in responses:\n",
    "    print(response.content)"
   ],
   "id": "f24ff03cf16772e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 逐个接收每个输入生成完成时的输出.在使用 batch_as_completed() 时，结果可能会乱序到达。每个结果都包含输入索引，以便在需要时匹配以重建原始顺序。\n",
    "for response in model.batch_as_completed([\n",
    "    \"Why do parrots have colorful feathers?\",\n",
    "    \"How do airplanes fly?\",\n",
    "    \"What is quantum computing?\"\n",
    "]):\n",
    "    print(response)"
   ],
   "id": "4cb3a35a7d81904f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.工具调用",
   "id": "a6d175abec11c3f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather at a location.\"\"\"\n",
    "    return f\"It's sunny in {location}.\"\n",
    "\n",
    "\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "response = model_with_tools.invoke(\"What's the weather like in Boston?\")\n",
    "\n",
    "for tool_call in response.tool_calls:\n",
    "    # View tool calls made by the model\n",
    "    print(f\"Tool: {tool_call['name']}\")\n",
    "    print(f\"Args: {tool_call['args']}\")"
   ],
   "id": "d214a2d8c650fcf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 工具执行循环",
   "id": "e9324cc61d64bf2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 将（可能多个）工具绑定到模型\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "# Step 1: 模型生成工具调用\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "# Step 2: 执行工具并收集结果\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    # 使用生成的参数执行该工具\n",
    "    tool_result = get_weather.invoke(tool_call)\n",
    "    messages.append(tool_result)\n",
    "\n",
    "# Step 3: 将结果传回模型以获得最终响应\n",
    "final_response = model_with_tools.invoke(messages)\n",
    "print(final_response.text)\n",
    "# \"The current weather in Boston is 72°F and sunny.\""
   ],
   "id": "2f97b4cb81de3d7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2.2 强制工具调用\n",
    "\n",
    "强制使用任何工具： \n",
    "```python\n",
    "model_with_tools = model.bind_tools([tool_1], tool_choice=\"any\")\n",
    "```\n",
    "\n",
    "强制使用特定工具\n",
    "```python\n",
    "model_with_tools = model.bind_tools([tool_1], tool_choice=\"tool_1\")\n",
    "```"
   ],
   "id": "3481e766e57a6d8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 并行工具调用\n",
   "id": "72b8b67a8c5ef9e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "response = model_with_tools.invoke(\n",
    "    \"What's the weather in Boston and Tokyo?\"\n",
    ")\n",
    "\n",
    "\n",
    "# The model may generate multiple tool calls\n",
    "print(response.tool_calls)\n",
    "# [\n",
    "#   {'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'call_1'},\n",
    "#   {'name': 'get_time', 'args': {'location': 'Tokyo'}, 'id': 'call_2'}\n",
    "# ]\n",
    "\n",
    "\n",
    "# Execute all tools (can be done in parallel with async)\n",
    "results = []\n",
    "for tool_call in response.tool_calls:\n",
    "    if tool_call['name'] == 'get_weather':\n",
    "        result = get_weather.invoke(tool_call)\n",
    "    # ...\n",
    "    results.append(result)\n",
    "    \n",
    "print( results)"
   ],
   "id": "b271bd0c6e16f768",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4 流式工具调用",
   "id": "3f104d5b64ab3cd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for chunk in model_with_tools.stream(\n",
    "    \"What's the weather in Boston and Tokyo?\"\n",
    "):\n",
    "    # Tool call chunks arrive progressively\n",
    "    if chunk.tool_call_chunks:\n",
    "        for tool_chunk in chunk.tool_call_chunks:\n",
    "            print(f\"Tool: {tool_chunk.get('name', '')}\")\n",
    "            print(f\"Args: {tool_chunk.get('args', '')}\")\n",
    "\n",
    "# Output:\n",
    "# Tool: get_weather            # Loop 1\n",
    "# Args:\n",
    "# Tool:                        # Loop 2\n",
    "# Args: {\"loc\n",
    "# Tool:                        # Loop 3\n",
    "# Args: ation\": \"BOS\"}\n",
    "# Tool: get_time               # Loop 4\n",
    "# Args:\n",
    "# Args:\n",
    "# Tool:                        # Loop 5\n",
    "# Args: {\"timezone\": \"Tokyo\"}"
   ],
   "id": "5147143df3209fe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gathered = None\n",
    "for chunk in model_with_tools.stream(\"What's the weather in Boston?\"):\n",
    "    gathered = chunk if gathered is None else gathered + chunk\n",
    "    print(gathered)"
   ],
   "id": "e469304569800b53",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
