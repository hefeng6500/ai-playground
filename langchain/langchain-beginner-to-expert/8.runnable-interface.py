"""
ç¬¬8èŠ‚ï¼šRunnable æ¥å£æ·±å…¥
=============================================

å­¦ä¹ ç›®æ ‡ï¼š
- æ·±å…¥ç†è§£ Runnable æ¥å£çš„è®¾è®¡ç†å¿µ
- æŒæ¡è‡ªå®šä¹‰ Runnable ç»„ä»¶å¼€å‘
- å­¦ä¼šæ„å»ºå¤æ‚çš„å¤„ç†é“¾æ¡
- äº†è§£å¹¶è¡Œå’Œåˆ†æ”¯å¤„ç†æŠ€æœ¯

å‰ç½®çŸ¥è¯†ï¼š
- å®Œæˆç¬¬1-7èŠ‚åŸºç¡€å†…å®¹

é‡ç‚¹æ¦‚å¿µï¼š
- Runnable æ˜¯ LangChain çš„æ ¸å¿ƒæŠ½è±¡
- æ‰€æœ‰ç»„ä»¶éƒ½å®ç°äº† Runnable æ¥å£
- æ”¯æŒç»„åˆã€å¹¶è¡Œã€åˆ†æ”¯ç­‰é«˜çº§æ“ä½œ
"""

import os
from typing import Any, Dict, List, Optional, Union
from abc import ABC, abstractmethod


def explain_runnable_concept():
    """
    è§£é‡Š Runnable æ¥å£çš„æ ¸å¿ƒæ¦‚å¿µ
    """
    print("\n" + "="*60)
    print("ğŸ”§ Runnable æ¥å£ï¼šLangChain çš„æ ¸å¿ƒ")
    print("="*60)
    
    print("""
ğŸ§© ä»€ä¹ˆæ˜¯ Runnableï¼Ÿ

æƒ³è±¡ä¹é«˜ç§¯æœ¨ï¼š
- æ¯ä¸ªç§¯æœ¨éƒ½æœ‰æ ‡å‡†çš„è¿æ¥æ¥å£ ğŸ”Œ
- ä¸åŒå½¢çŠ¶çš„ç§¯æœ¨å¯ä»¥éšæ„ç»„åˆ ğŸ§±
- ç»„åˆåçš„ç§¯æœ¨ä»ç„¶å¯ä»¥ç»§ç»­ç»„åˆ ğŸ—ï¸

Runnable å°±æ˜¯ LangChain çš„"è¿æ¥æ¥å£"ï¼š
- æ‰€æœ‰ç»„ä»¶éƒ½å®ç° Runnable æ¥å£
- å¯ä»¥ç”¨ | æ“ä½œç¬¦è¿æ¥
- ç»„åˆåçš„é“¾æ¡ä¹Ÿæ˜¯ Runnable

ğŸ¯ æ ¸å¿ƒæ–¹æ³•ï¼š
- invoke()ï¼šåŒæ­¥æ‰§è¡Œ
- stream()ï¼šæµå¼æ‰§è¡Œ  
- batch()ï¼šæ‰¹é‡æ‰§è¡Œ
- ainvoke()ï¼šå¼‚æ­¥æ‰§è¡Œ
- astream()ï¼šå¼‚æ­¥æµå¼æ‰§è¡Œ
- abatch()ï¼šå¼‚æ­¥æ‰¹é‡æ‰§è¡Œ
    """)
    
    print("ğŸ“Š Runnable ç”Ÿæ€ç³»ç»Ÿï¼š")
    components = [
        "ğŸ§  LLMï¼šè¯­è¨€æ¨¡å‹",
        "ğŸ“ PromptTemplateï¼šæç¤ºæ¨¡æ¿", 
        "ğŸ”§ OutputParserï¼šè¾“å‡ºè§£æå™¨",
        "ğŸ”— RunnableSequenceï¼šåºåˆ—é“¾",
        "ğŸ”€ RunnableParallelï¼šå¹¶è¡Œé“¾",
        "ğŸ¯ RunnableLambdaï¼šè‡ªå®šä¹‰å‡½æ•°"
    ]
    
    for component in components:
        print(f"   {component}")


def basic_runnable_demo():
    """
    åŸºç¡€ Runnable æ“ä½œæ¼”ç¤º
    """
    print("\n" + "="*60)
    print("ğŸ¯ åŸºç¡€ Runnable æ“ä½œ")
    print("="*60)
    
    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        from langchain_core.runnables import RunnableLambda
        
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            print("âŒ è¯·å…ˆé…ç½® DEEPSEEK_API_KEY")
            return
        
        print("ğŸ”§ åˆ›å»ºåŸºç¡€ç»„ä»¶")
        print("-" * 30)
        
        # åˆ›å»ºç»„ä»¶
        prompt = ChatPromptTemplate.from_template("è¯·ç®€è¦å›ç­”ï¼š{question}")
        model = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=api_key,
            openai_api_base="https://api.deepseek.com",
            temperature=0.7
        )
        parser = StrOutputParser()
        
        # æ¯ä¸ªç»„ä»¶éƒ½æ˜¯ Runnable
        print(f"âœ… Prompt æ˜¯ Runnable: {hasattr(prompt, 'invoke')}")
        print(f"âœ… Model æ˜¯ Runnable: {hasattr(model, 'invoke')}")
        print(f"âœ… Parser æ˜¯ Runnable: {hasattr(parser, 'invoke')}")
        
        print("\nğŸ”— ç»„åˆæˆé“¾æ¡")
        print("-" * 30)
        
        # ç»„åˆæˆé“¾æ¡
        chain = prompt | model | parser
        print(f"âœ… Chain ä¹Ÿæ˜¯ Runnable: {hasattr(chain, 'invoke')}")
        
        print(f"ğŸ¯ æµ‹è¯•ä¸åŒçš„æ‰§è¡Œæ–¹æ³•...")
        
        test_input = {"question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"}
        
        # 1. invokeï¼šåŒæ­¥æ‰§è¡Œ
        print("\n1ï¸âƒ£ invoke() - åŒæ­¥æ‰§è¡Œï¼š")
        result = chain.invoke(test_input)
        print(f"ç»“æœï¼š{result[:100]}...")
        
        # 2. batchï¼šæ‰¹é‡æ‰§è¡Œ
        print("\n2ï¸âƒ£ batch() - æ‰¹é‡æ‰§è¡Œï¼š")
        batch_inputs = [
            {"question": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"},
            {"question": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ"},
            {"question": "ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ"}
        ]
        
        batch_results = chain.batch(batch_inputs)
        for i, result in enumerate(batch_results, 1):
            print(f"   ç»“æœ{i}ï¼š{result[:50]}...")
        
        # 3. streamï¼šæµå¼æ‰§è¡Œ
        print("\n3ï¸âƒ£ stream() - æµå¼æ‰§è¡Œï¼š")
        print("æµå¼è¾“å‡ºï¼š", end="", flush=True)
        for chunk in chain.stream({"question": "ä»€ä¹ˆæ˜¯åŒºå—é“¾ï¼Ÿ"}):
            print(chunk, end="", flush=True)
        print("\n")
        
        print("âœ… Runnable æ¥å£çš„ç»Ÿä¸€æ€§è®©æ“ä½œå˜å¾—ç®€å•ï¼")
        
    except Exception as e:
        print(f"âŒ åŸºç¡€ Runnable æ¼”ç¤ºå¤±è´¥ï¼š{e}")


def custom_runnable_demo():
    """
    è‡ªå®šä¹‰ Runnable ç»„ä»¶æ¼”ç¤º
    """
    print("\n" + "="*60)
    print("ğŸ› ï¸  è‡ªå®šä¹‰ Runnable ç»„ä»¶")
    print("="*60)
    
    try:
        from langchain_core.runnables import RunnableLambda
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        import json
        import re
        
        print("ğŸ¯ åœºæ™¯ï¼šæ–‡æœ¬åˆ†æå¤„ç†é“¾")
        print("-" * 30)
        
        # è‡ªå®šä¹‰å‡½æ•°1ï¼šæ–‡æœ¬é¢„å¤„ç†
        def preprocess_text(input_data):
            """æ–‡æœ¬é¢„å¤„ç†"""
            text = input_data.get("text", "")
            
            # æ¸…ç†æ–‡æœ¬
            cleaned = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)  # åªä¿ç•™ä¸­è‹±æ–‡å’Œæ•°å­—
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()  # æ ‡å‡†åŒ–ç©ºæ ¼
            
            result = {
                "original_text": text,
                "cleaned_text": cleaned,
                "char_count": len(cleaned),
                "word_count": len(cleaned.split())
            }
            
            print(f"ğŸ§¹ é¢„å¤„ç†å®Œæˆï¼š{len(text)} â†’ {len(cleaned)} å­—ç¬¦")
            return result
        
        # è‡ªå®šä¹‰å‡½æ•°2ï¼šæƒ…æ„Ÿåˆ†æ
        def analyze_sentiment(input_data):
            """ç®€å•çš„æƒ…æ„Ÿåˆ†æ"""
            text = input_data.get("cleaned_text", "")
            
            # ç®€å•çš„å…³é”®è¯æƒ…æ„Ÿåˆ†æ
            positive_words = ["å¥½", "æ£’", "ä¼˜ç§€", "å–œæ¬¢", "å¼€å¿ƒ", "æ»¡æ„", "æ¨è"]
            negative_words = ["å·®", "å", "ç³Ÿç³•", "è®¨åŒ", "æ„¤æ€’", "å¤±æœ›", "ä¸å¥½"]
            
            pos_count = sum(1 for word in positive_words if word in text)
            neg_count = sum(1 for word in negative_words if word in text)
            
            if pos_count > neg_count:
                sentiment = "ç§¯æ"
                score = min(0.8, 0.5 + pos_count * 0.1)
            elif neg_count > pos_count:
                sentiment = "æ¶ˆæ" 
                score = max(0.2, 0.5 - neg_count * 0.1)
            else:
                sentiment = "ä¸­æ€§"
                score = 0.5
            
            result = input_data.copy()
            result.update({
                "sentiment": sentiment,
                "sentiment_score": score,
                "positive_words": pos_count,
                "negative_words": neg_count
            })
            
            print(f"ğŸ˜Š æƒ…æ„Ÿåˆ†æï¼š{sentiment} (å¾—åˆ†: {score:.2f})")
            return result
        
        # è‡ªå®šä¹‰å‡½æ•°3ï¼šç”ŸæˆæŠ¥å‘Š
        def generate_report(input_data):
            """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
            report = f"""
ğŸ“Š æ–‡æœ¬åˆ†ææŠ¥å‘Š
==================
ğŸ“ åŸæ–‡é•¿åº¦ï¼š{input_data['char_count']} å­—ç¬¦ï¼Œ{input_data['word_count']} è¯
ğŸ˜Š æƒ…æ„Ÿå€¾å‘ï¼š{input_data['sentiment']} (ç½®ä¿¡åº¦: {input_data['sentiment_score']:.2f})
ğŸ“ˆ ç§¯æè¯æ±‡ï¼š{input_data['positive_words']} ä¸ª
ğŸ“‰ æ¶ˆæè¯æ±‡ï¼š{input_data['negative_words']} ä¸ª

ğŸ’¡ åˆ†æå»ºè®®ï¼š
"""
            if input_data['sentiment'] == "ç§¯æ":
                report += "æ–‡æœ¬æ•´ä½“æƒ…æ„Ÿç§¯æï¼Œä¼ è¾¾æ­£é¢ä¿¡æ¯ã€‚"
            elif input_data['sentiment'] == "æ¶ˆæ":
                report += "æ–‡æœ¬æƒ…æ„Ÿåæ¶ˆæï¼Œå¯èƒ½éœ€è¦å…³æ³¨ç›¸å…³é—®é¢˜ã€‚"
            else:
                report += "æ–‡æœ¬æƒ…æ„Ÿä¸­æ€§ï¼Œå®¢è§‚æè¿°ä¸ºä¸»ã€‚"
            
            result = input_data.copy()
            result["analysis_report"] = report
            
            print("ğŸ“‹ æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return result
        
        # å°†å‡½æ•°è½¬ä¸º Runnable
        preprocessor = RunnableLambda(preprocess_text)
        sentiment_analyzer = RunnableLambda(analyze_sentiment)
        report_generator = RunnableLambda(generate_report)
        
        # ç»„åˆæˆåˆ†æé“¾
        analysis_chain = preprocessor | sentiment_analyzer | report_generator
        
        print("ğŸ§ª æµ‹è¯•æ–‡æœ¬åˆ†æé“¾...")
        
        test_texts = [
            "è¿™ä¸ªäº§å“çœŸçš„å¾ˆæ£’ï¼æˆ‘éå¸¸å–œæ¬¢ï¼Œå¼ºçƒˆæ¨èç»™å¤§å®¶ã€‚",
            "æœåŠ¡å¤ªå·®äº†ï¼Œå®Œå…¨ä¸æ»¡æ„ï¼Œå¾ˆå¤±æœ›ã€‚",
            "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥ã€‚"
        ]
        
        for i, text in enumerate(test_texts, 1):
            print(f"\nğŸ“ æµ‹è¯•æ–‡æœ¬ {i}ï¼š{text}")
            print("="*50)
            
            result = analysis_chain.invoke({"text": text})
            print(result["analysis_report"])
        
        print("\nâœ… è‡ªå®šä¹‰ Runnable çš„ä¼˜åŠ¿ï¼š")
        advantages = [
            "ğŸ”§ é«˜åº¦å®šåˆ¶ï¼šå®ç°ç‰¹å®šä¸šåŠ¡é€»è¾‘",
            "ğŸ”— æ— ç¼é›†æˆï¼šä¸å…¶ä»–ç»„ä»¶å®Œç¾é…åˆ",
            "ğŸ§ª æ˜“äºæµ‹è¯•ï¼šæ¯ä¸ªç»„ä»¶å¯å•ç‹¬æµ‹è¯•",
            "ğŸ“ˆ å¯æ‰©å±•ï¼šå®¹æ˜“æ·»åŠ æ–°çš„å¤„ç†æ­¥éª¤"
        ]
        
        for advantage in advantages:
            print(f"   {advantage}")
        
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰ Runnable æ¼”ç¤ºå¤±è´¥ï¼š{e}")


def parallel_runnable_demo():
    """
    å¹¶è¡Œ Runnable æ¼”ç¤º
    """
    print("\n" + "="*60)
    print("ğŸ”€ å¹¶è¡Œå¤„ç†ï¼šRunnableParallel")
    print("="*60)
    
    try:
        from langchain_core.runnables import RunnableParallel, RunnableLambda
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        import time
        
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            return
        
        print("ğŸ¯ åœºæ™¯ï¼šå¤šè§’åº¦æ–‡æœ¬åˆ†æ")
        print("-" * 30)
        
        # åˆ›å»ºæ¨¡å‹
        model = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=api_key,
            openai_api_base="https://api.deepseek.com",
            temperature=0.5
        )
        parser = StrOutputParser()
        
        # åˆ›å»ºä¸åŒçš„åˆ†æé“¾
        summary_chain = (
            ChatPromptTemplate.from_template("è¯·ç”¨ä¸€å¥è¯æ€»ç»“ï¼š{text}") |
            model | parser
        )
        
        keywords_chain = (
            ChatPromptTemplate.from_template("æå–3ä¸ªå…³é”®è¯ï¼š{text}") |
            model | parser
        )
        
        sentiment_chain = (
            ChatPromptTemplate.from_template("åˆ†ææƒ…æ„Ÿå€¾å‘ï¼š{text}") |
            model | parser
        )
        
        # åˆ›å»ºå¹¶è¡Œå¤„ç†é“¾
        parallel_chain = RunnableParallel({
            "summary": summary_chain,
            "keywords": keywords_chain, 
            "sentiment": sentiment_chain
        })
        
        print("ğŸ§ª æµ‹è¯•å¹¶è¡Œå¤„ç†...")
        
        test_text = """
        äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨è¿‘å¹´æ¥å‘å±•è¿…é€Ÿï¼Œæ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œçš„çªç ´
        è®©AIåœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚
        ç„¶è€Œï¼ŒAIçš„å‘å±•ä¹Ÿå¸¦æ¥äº†ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚æ•°æ®éšç§ã€ç®—æ³•åè§ç­‰é—®é¢˜
        éœ€è¦æˆ‘ä»¬è®¤çœŸå¯¹å¾…å’Œè§£å†³ã€‚
        """
        
        print(f"ğŸ“ åˆ†ææ–‡æœ¬ï¼š{test_text.strip()}")
        
        # æµ‹è¯•ä¸²è¡Œ vs å¹¶è¡Œçš„æ€§èƒ½å·®å¼‚
        print("\nâ±ï¸  æ€§èƒ½å¯¹æ¯”ï¼š")
        
        # ä¸²è¡Œæ‰§è¡Œ
        start_time = time.time()
        serial_results = {
            "summary": summary_chain.invoke({"text": test_text}),
            "keywords": keywords_chain.invoke({"text": test_text}),
            "sentiment": sentiment_chain.invoke({"text": test_text})
        }
        serial_time = time.time() - start_time
        
        print(f"ğŸ”„ ä¸²è¡Œæ‰§è¡Œæ—¶é—´ï¼š{serial_time:.2f} ç§’")
        
        # å¹¶è¡Œæ‰§è¡Œ
        start_time = time.time()
        parallel_results = parallel_chain.invoke({"text": test_text})
        parallel_time = time.time() - start_time
        
        print(f"âš¡ å¹¶è¡Œæ‰§è¡Œæ—¶é—´ï¼š{parallel_time:.2f} ç§’")
        print(f"ğŸš€ æ€§èƒ½æå‡ï¼š{((serial_time - parallel_time) / serial_time * 100):.1f}%")
        
        print("\nğŸ“Š å¹¶è¡Œåˆ†æç»“æœï¼š")
        print("="*50)
        
        for key, value in parallel_results.items():
            print(f"ğŸ“‹ {key.upper()}:")
            print(f"   {value}")
            print()
        
        print("âœ… å¹¶è¡Œå¤„ç†çš„ä¼˜åŠ¿ï¼š")
        advantages = [
            "âš¡ æ›´å¿«é€Ÿåº¦ï¼šåŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡",
            "ğŸ’¾ èµ„æºåˆ©ç”¨ï¼šå……åˆ†åˆ©ç”¨ç½‘ç»œå¸¦å®½",
            "ğŸ¯ ç‹¬ç«‹æ€§ï¼šæ¯ä¸ªåˆ†æ”¯ç‹¬ç«‹å¤„ç†",
            "ğŸ”§ æ˜“æ‰©å±•ï¼šå®¹æ˜“æ·»åŠ æ–°çš„å¹¶è¡Œåˆ†æ”¯"
        ]
        
        for advantage in advantages:
            print(f"   {advantage}")
        
    except Exception as e:
        print(f"âŒ å¹¶è¡Œ Runnable æ¼”ç¤ºå¤±è´¥ï¼š{e}")


def conditional_runnable_demo():
    """
    æ¡ä»¶åˆ†æ”¯ Runnable æ¼”ç¤º
    """
    print("\n" + "="*60)
    print("ğŸ¯ æ¡ä»¶åˆ†æ”¯å¤„ç†")
    print("="*60)
    
    try:
        from langchain_core.runnables import RunnableLambda, RunnableBranch
        from langchain_openai import ChatOpenAI
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            return
        
        print("ğŸ¯ åœºæ™¯ï¼šæ™ºèƒ½å®¢æœè·¯ç”±ç³»ç»Ÿ")
        print("-" * 30)
        
        # åˆ›å»ºæ¨¡å‹å’Œè§£æå™¨
        model = ChatOpenAI(
            model="deepseek-chat",
            openai_api_key=api_key,
            openai_api_base="https://api.deepseek.com",
            temperature=0.3
        )
        parser = StrOutputParser()
        
        # åˆ†ç±»å‡½æ•°
        def classify_query(input_data):
            """åˆ†ç±»ç”¨æˆ·æŸ¥è¯¢"""
            query = input_data.get("query", "").lower()
            
            if any(word in query for word in ["ä»·æ ¼", "è´¹ç”¨", "å¤šå°‘é’±", "æ”¶è´¹"]):
                category = "pricing"
            elif any(word in query for word in ["æŠ€æœ¯", "å¦‚ä½•", "æ€ä¹ˆ", "æ•™ç¨‹"]):
                category = "technical"
            elif any(word in query for word in ["æŠ•è¯‰", "é—®é¢˜", "æ•…éšœ", "ä¸æ»¡"]):
                category = "complaint"
            else:
                category = "general"
            
            result = input_data.copy()
            result["category"] = category
            print(f"ğŸ·ï¸  æŸ¥è¯¢åˆ†ç±»ï¼š{category}")
            return result
        
        # ä¸åŒç±»å‹çš„å¤„ç†é“¾
        pricing_chain = (
            ChatPromptTemplate.from_template(
                "ä½œä¸ºé”€å”®ä»£è¡¨ï¼Œå›ç­”ä»·æ ¼é—®é¢˜ï¼š{query}"
            ) | model | parser
        )
        
        technical_chain = (
            ChatPromptTemplate.from_template(
                "ä½œä¸ºæŠ€æœ¯æ”¯æŒï¼Œæä¾›æŠ€æœ¯å¸®åŠ©ï¼š{query}"
            ) | model | parser
        )
        
        complaint_chain = (
            ChatPromptTemplate.from_template(
                "ä½œä¸ºå®¢æœä¸»ç®¡ï¼Œå¤„ç†æŠ•è¯‰é—®é¢˜ï¼š{query}"
            ) | model | parser
        )
        
        general_chain = (
            ChatPromptTemplate.from_template(
                "ä½œä¸ºå®¢æœä»£è¡¨ï¼Œå›ç­”ä¸€èˆ¬é—®é¢˜ï¼š{query}"
            ) | model | parser
        )
        
        # åˆ›å»ºåˆ†ç±»å™¨
        classifier = RunnableLambda(classify_query)
        
        # åˆ›å»ºæ¡ä»¶åˆ†æ”¯
        def route_query(input_data):
            """è·¯ç”±æŸ¥è¯¢åˆ°å¯¹åº”çš„å¤„ç†é“¾"""
            category = input_data.get("category", "general")
            
            if category == "pricing":
                return pricing_chain.invoke(input_data)
            elif category == "technical":
                return technical_chain.invoke(input_data)
            elif category == "complaint":
                return complaint_chain.invoke(input_data)
            else:
                return general_chain.invoke(input_data)
        
        router = RunnableLambda(route_query)
        
        # å®Œæ•´çš„å®¢æœç³»ç»Ÿ
        customer_service_chain = classifier | router
        
        print("ğŸ§ª æµ‹è¯•æ™ºèƒ½å®¢æœè·¯ç”±...")
        
        test_queries = [
            "ä½ ä»¬çš„äº§å“å¤šå°‘é’±ï¼Ÿæœ‰ä¼˜æƒ å—ï¼Ÿ",
            "å¦‚ä½•é…ç½®Pythonå¼€å‘ç¯å¢ƒï¼Ÿ",
            "æˆ‘å¯¹ä½ ä»¬çš„æœåŠ¡å¾ˆä¸æ»¡æ„ï¼Œè¦æŠ•è¯‰ï¼",
            "ä½ ä»¬å…¬å¸åœ¨å“ªé‡Œï¼Ÿ"
        ]
        
        for i, query in enumerate(test_queries, 1):
            print(f"\nğŸ“ å®¢æˆ·æŸ¥è¯¢ {i}ï¼š{query}")
            print("="*50)
            
            response = customer_service_chain.invoke({"query": query})
            print(f"ğŸ¤– å®¢æœå›å¤ï¼š{response}")
        
        print("\nâœ… æ¡ä»¶åˆ†æ”¯çš„åº”ç”¨åœºæ™¯ï¼š")
        use_cases = [
            "ğŸ¯ æ™ºèƒ½è·¯ç”±ï¼šæ ¹æ®å†…å®¹åˆ†å‘åˆ°ä¸åŒå¤„ç†å™¨",
            "ğŸ”§ é”™è¯¯å¤„ç†ï¼šæ ¹æ®é”™è¯¯ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼",
            "ğŸ“Š æ•°æ®å¤„ç†ï¼šæ ¹æ®æ•°æ®æ ¼å¼é€‰æ‹©è§£æå™¨",
            "ğŸ® æ¸¸æˆé€»è¾‘ï¼šæ ¹æ®ç©å®¶è¡Œä¸ºè§¦å‘ä¸åŒå‰§æƒ…"
        ]
        
        for use_case in use_cases:
            print(f"   {use_case}")
        
    except Exception as e:
        print(f"âŒ æ¡ä»¶åˆ†æ”¯æ¼”ç¤ºå¤±è´¥ï¼š{e}")


def next_lesson_preview():
    """
    æ€»ç»“å’Œé¢„å‘Š
    """
    print("\n" + "="*60)
    print("ğŸ“ ç¬¬8èŠ‚æ€»ç»“ & ç¬¬9èŠ‚é¢„å‘Š")
    print("="*60)
    
    print("ğŸ‰ ç¬¬8èŠ‚ä½ æŒæ¡äº†ï¼š")
    learned = [
        "âœ… æ·±å…¥ç†è§£ Runnable æ¥å£è®¾è®¡",
        "âœ… æŒæ¡è‡ªå®šä¹‰ Runnable ç»„ä»¶å¼€å‘",
        "âœ… å­¦ä¼šå¹¶è¡Œå¤„ç†æå‡æ€§èƒ½",
        "âœ… äº†è§£æ¡ä»¶åˆ†æ”¯å’Œæ™ºèƒ½è·¯ç”±"
    ]
    
    for item in learned:
        print(f"   {item}")
    
    print("\nğŸ“š ç¬¬9èŠ‚é¢„å‘Šï¼šã€Šæ–‡æ¡£å¤„ç†ä¸ RAG åŸºç¡€ã€‹")
    print("ä½ å°†å­¦åˆ°ï¼š")
    next_topics = [
        "ğŸ“„ æ–‡æ¡£åŠ è½½å’Œé¢„å¤„ç†",
        "âœ‚ï¸  æ–‡æœ¬åˆ†å‰²ç­–ç•¥",
        "ğŸ” ç›¸ä¼¼æ€§æ£€ç´¢åŸºç¡€",
        "ğŸ§  RAG ç³»ç»Ÿæ„å»ºå…¥é—¨"
    ]
    
    for topic in next_topics:
        print(f"   {topic}")


def main():
    """
    ä¸»å‡½æ•°ï¼šç¬¬8èŠ‚å®Œæ•´å­¦ä¹ æµç¨‹
    """
    print("ğŸ¯ LangChain å…¥é—¨åˆ°ç²¾é€š - ç¬¬8èŠ‚")
    print("ğŸ”§ Runnable æ¥å£æ·±å…¥")
    print("ğŸ“š å‰ç½®ï¼šå®Œæˆç¬¬1-7èŠ‚")
    
    # 1. è§£é‡Š Runnable æ¦‚å¿µ
    explain_runnable_concept()
    
    # 2. åŸºç¡€ Runnable æ“ä½œ
    basic_runnable_demo()
    
    # 3. è‡ªå®šä¹‰ Runnable ç»„ä»¶
    custom_runnable_demo()
    
    # 4. å¹¶è¡Œå¤„ç†
    parallel_runnable_demo()
    
    # 5. æ¡ä»¶åˆ†æ”¯
    conditional_runnable_demo()
    
    # 6. æ€»ç»“é¢„å‘Š
    next_lesson_preview()
    
    print("\n" + "="*60)
    print("ğŸ‰ ç¬¬8èŠ‚å®Œæˆï¼")
    print("ğŸ”§ ä½ å·²ç»æ˜¯ Runnable æ¥å£ä¸“å®¶äº†ï¼")
    print("="*60)


if __name__ == "__main__":
    # æ£€æŸ¥ç¯å¢ƒ
    if not os.getenv("DEEPSEEK_API_KEY"):
        print("âš ï¸  è¯·å…ˆé…ç½® DEEPSEEK_API_KEY")
        import getpass
        temp_key = getpass.getpass("è¯·è¾“å…¥ DeepSeek API Key: ")
        if temp_key:
            os.environ["DEEPSEEK_API_KEY"] = temp_key
    
    # è¿è¡Œä¸»ç¨‹åº
    main()
    
    print("\nğŸ”— æœ¬èŠ‚å‚è€ƒèµ„æºï¼š")
    print("   ğŸ“– LangChain Runnable å®˜æ–¹æ–‡æ¡£")
    print("   ğŸ’» å‡½æ•°å¼ç¼–ç¨‹æœ€ä½³å®è·µ")
    print("   ğŸ”§ ç»„ä»¶åŒ–æ¶æ„è®¾è®¡æ¨¡å¼")