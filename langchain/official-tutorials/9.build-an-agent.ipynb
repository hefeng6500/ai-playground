{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60eeafb4",
   "metadata": {},
   "source": [
    "# build an agent 构建代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f56751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关功能模块\n",
    "from langchain.chat_models import init_chat_model  # 初始化聊天模型\n",
    "from langchain_tavily import TavilySearch  # Tavily 搜索工具\n",
    "from langgraph.checkpoint.memory import MemorySaver  # 内存保存器，用于持久化对话状态\n",
    "from langgraph.prebuilt import create_react_agent  # 创建 ReAct 代理\n",
    "\n",
    "# 创建代理\n",
    "memory = MemorySaver()  # 创建内存保存器实例\n",
    "# model = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")  # 可选择 Claude 模型\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")  # 初始化 OpenAI GPT-4o-mini 模型\n",
    "search = TavilySearch(max_results=2)  # 创建 Tavily 搜索工具，限制最多返回 2 个结果\n",
    "tools = [search]  # 将搜索工具放入工具列表\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)  # 创建 ReAct 代理执行器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f593e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用代理\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}  # 配置线程 ID，用于区分不同的对话会话\n",
    "\n",
    "input_message = {\n",
    "    \"role\": \"user\",  # 消息角色为用户\n",
    "    \"content\": \"Hi, I'm Bob and I live in SF.\",  # 用户介绍自己\n",
    "}\n",
    "# 流式调用代理，获取响应\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()  # 打印最新的消息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046caac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试代理的记忆能力和工具使用\n",
    "input_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What's the weather where I live?\",  # 询问天气，代理需要记住用户住在 SF\n",
    "}\n",
    "\n",
    "# 代理会自动调用搜索工具查询旧金山的天气\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()  # 显示代理的推理过程和最终回答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5bb1b",
   "metadata": {},
   "source": [
    "### 定义工具\n",
    "\n",
    "在构建代理之前，我们需要定义代理可以使用的工具。\n",
    "这里我们使用 Tavily 搜索工具来获取实时信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2019cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# 创建 Tavily 搜索工具实例\n",
    "search = TavilySearch(max_results=2)  # 限制搜索结果数量为 2\n",
    "# 测试搜索工具的功能\n",
    "search_results = search.invoke(\"What is the weather in SF\")\n",
    "print(search_results)\n",
    "# 如果需要，我们可以创建其他工具\n",
    "# 将所有需要的工具放入列表中，供代理使用\n",
    "tools = [search]  # 工具列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 初始化聊天模型（这里使用了一个示例模型名）\n",
    "model = init_chat_model(\"gpt-4.1\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be52431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试基础模型功能\n",
    "query = \"Hi!\"\n",
    "response = model.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "response.text()  # 获取模型的文本响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将工具绑定到模型上\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# 测试绑定工具后的模型行为\n",
    "query = \"Hi!\"\n",
    "response = model_with_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "\n",
    "# 查看模型的响应内容和工具调用情况\n",
    "print(f\"Message content: {response.text()}\\n\")\n",
    "print(f\"Tool calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7eabed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试需要使用工具的查询\n",
    "query = \"Search for the weather in ShenZhen\"\n",
    "response = model_with_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "\n",
    "# 这次模型会识别需要调用搜索工具\n",
    "print(f\"Message content: {response.text()}\\n\")\n",
    "print(f\"Tool calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d69c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 创建 ReAct 代理（无内存版本）\n",
    "agent_executor = create_react_agent(model, tools)\n",
    "\n",
    "# 测试代理的基本对话功能\n",
    "input_message = {\"role\": \"user\", \"content\": \"Hi!\"}\n",
    "response = agent_executor.invoke({\"messages\": [input_message]})\n",
    "\n",
    "# 打印所有消息（包括用户输入和代理响应）\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()\n",
    "\n",
    "# 测试代理调用工具的能力\n",
    "input_message = {\"role\": \"user\", \"content\": \"Search for the weather in shenzhen\"}\n",
    "response = agent_executor.invoke({\"messages\": [input_message]})\n",
    "\n",
    "# 显示完整的对话流程：用户输入 -> 工具调用 -> 工具结果 -> 代理回答\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fada13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流式消息输出（逐步显示代理的推理过程）\n",
    "for step in agent_executor.stream({\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()  # 显示每一步的最新消息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流式输出代理的文本响应（实时显示生成的文本）\n",
    "for step, metadata in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, stream_mode=\"messages\"\n",
    "):\n",
    "    # 只显示代理节点生成的文本内容\n",
    "    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
    "        print(text, end=\"|\")  # 用 | 分隔每个文本块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d871b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加内存功能到代理\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()  # 创建内存保存器\n",
    "\n",
    "# 创建带有内存功能的代理\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "# 配置会话 ID，用于区分不同的对话\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "# 用户自我介绍\n",
    "input_message = {\"role\": \"user\", \"content\": \"Hi, I'm Bob!\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试代理的记忆能力\n",
    "input_message = {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()  # 代理应该记住用户的名字是 Bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1552ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用不同的会话 ID 测试内存隔离\n",
    "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
    "\n",
    "# 在新的会话中询问相同的问题\n",
    "input_message = {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()  # 代理不应该知道用户的名字，因为这是新的会话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013effe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
